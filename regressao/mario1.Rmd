---
title: "Regressão Linear"
author: "Nazareno Andrade"
output: 
  html_notebook:
    theme: readable
    fig_width: 7
    toc: true
    toc_float: true

---

```{r message=FALSE, warning=FALSE}
library(openintro)
library(tidyverse)
library(ggbeeswarm)
library(modelr)
library(broom)
theme_set(theme_bw())
```


# A intuição

Estamos interessados na relação entre 

```{r}
mario <- read_delim("marioKart.txt", delim = "\t", col_types = "diicdddcicic") %>% 
  filter(totalPr < 100)

ggplot(mario, aes(x = totalPr, y = nBids)) + 
  geom_point(alpha = 0.4, size = .5)
```

No olho:

```{r}
ggplot(mario, aes(x = totalPr, y = nBids)) + 
  geom_point(alpha = 0.4, size = .8) + 
  geom_abline(slope = 0, intercept = 0, color  = "red") 
```

Quantificando a qualidade do modelo:

```{r}
modelo = function(totalPr, slope, intercept){
  return(slope * totalPr + intercept)
}

nossas_estimativas = mario %>% 
  select(totalPr, nBids) %>% 
  mutate(
    segundo_modelo = modelo(totalPr, 0, 50), 
    residuo = nBids - segundo_modelo, 
    residuo_quad = residuo**2 # para que fique tudo positivo
  )

fit_modelo = nossas_estimativas %>% summarise(sse = sum(residuo_quad)) %>% pull(sse)
```

```{r}
ggplot(mario, aes(x = "", y = nBids)) + 
  geom_quasirandom(size = .5, width = .2) + 
  geom_point(aes(y = mean(nBids)), color = "red", size = 3)
```


```{r}
usando_media = mario %>% 
  select(totalPr, nBids) %>% 
  mutate(
    segundo_modelo = mean(nBids), 
    residuo = nBids - segundo_modelo, 
    residuo_quad = residuo**2
  )

fit_media = usando_media %>% summarise(sse = sum(residuo_quad)) %>% pull(sse)
```

Comparando: de quanto é a redução no erro usando nosso modelo comparado com o da média?

```{r}
(fit_media - fit_modelo)/fit_media
```

## Agora de uma forma menos manual

lm  == linear model

```{r}
ggplot(mario, aes(x = totalPr, y = nBids)) + 
  geom_point(alpha = 0.4) + 
  geom_smooth(method = "lm", se = FALSE)
```



```{r}
mod <- lm(totalPr ~ nBids, 
          data = mario)

# broom, que acho mais recomendável: 
tidy(mod)
glance(mod) # depois falaremos desse

mario %>% 
  add_predictions(model = mod) %>% # add o que o modelo estima p cada hs_grad
  ggplot(mapping = aes(x = nBids, y = totalPr)) + 
  geom_point(alpha = 0.4, size = 1.5) + 
  geom_line(aes(y = pred), colour = "red")
```

```{r}
mario %>% 
  add_residuals(model = mod) %>% 
  ggplot(aes(totalPr, resid)) + 
  geom_point(alpha = .4, size = .5) + 
  geom_hline(yintercept = 0, colour = "blue")
```

## R^2 é a variância da variável de saída explicada pelo modelo

```{r}
# variância de y
var.y2 <- sum((mario$nBids - mean(mario$nBids))^2)
# variância dos resíduos do modelo
var.residuals <- sum(mod$residuals^2)

#calculando e conferindo o R^2
(var.y2 - var.residuals)/var.y2
rsquare(mod, data = mario)

glance(mod)
```

Em outras situações, outras medidas de erro podem ser úteis

```{r}
rmse(mod, mario)
mae(mod, mario)
qae(mod, mario)
```

## Bootstrap para inferência sobre os parâmetros do modelo

Trabalhando com uma amostra, geralmente queremos inferir o intervalo de confiança para os coeficientes do modelo que descreve a relação que estamos modelando *na população* de onde veio nossa amostra. 

### Versão 1

```{r}
library(purrr)
boot <- modelr::bootstrap(mtcars, 100)

models <- map(boot$strap, ~ lm(mpg ~ wt, data = .))
tidied <- map_df(models, broom::tidy, .id = "id")

tidied %>% 
  ggplot(aes(x = estimate)) + 
  geom_histogram(bins = 30) + 
  facet_grid(. ~ term, scale = "free")
```


### Versão 2

```{r}
library(boot)
library(ISLR) # dados
attach(Auto)
```

Usando o pacote `boot` é preciso criar a função que será usada no bootstrap:

```{r}
boot.fn <- function(data, index) {
  return(coef(lm(mpg ~ horsepower, data=Auto, subset = index)))
}
boot.fn(mario, 1:392)
```

```{r}
regressao.b = boot(mario, boot.fn, 1000)
# tidy(regressao.b, conf.int = TRUE, conf.method = "perc") tidy(boot.out) parece bugado em 2017-06-13

plot(regressao.b, index=1) # intercept 
plot(regressao.b, index=2) # horsepower
boot.ci(regressao.b, type = "bca", index = 1) 
boot.ci(regressao.b, type = "bca", index = 2)
```

### Opção com outro pacote

```{r}
library("simpleboot")
modelo.simples = lm(totalPr ~ nBids, data = mario)
modelo.boot = lm.boot(modelo.simples, R = 1000)
summary(modelo.boot)
perc(modelo.boot, c(.025, .975))
```

# Relação entre aumento e nBids

```{r}
mario2 <- mario %>% mutate(aumento = totalPr- startPr)

modelo2 = lm(aumento ~ nBids, data= mario2)
tidy(modelo2)
glance(modelo2)

tidy(modelo2, conf.int = TRUE, conf.level = .95) %>% select(-p.value)

```

```{r}

mario2 %>% 
  add_predictions(model = modelo2) %>% # add o que o modelo estima p cada hs_grad
  ggplot(mapping = aes(x = nBids, y = aumento)) + 
  geom_point(alpha = 0.9, size = 1.5) + 
  geom_line(aes(y = pred), colour = "red")

```

# Relação entre totalPr e stockPhoto

```{r}

modelo3 = lm(totalPr ~ stockPhoto, data= mario2)
tidy(modelo3)
glance(modelo3)

tidy(modelo3, conf.int = TRUE, conf.level = .95) %>% select(-p.value)

```

```{r}

mario2 %>% 
  add_predictions(model = modelo2) %>% # add o que o modelo estima p cada hs_grad
  ggplot(mapping = aes(x = stockPhoto, y = totalPr)) + 
  geom_point(alpha = 0.9, size = 1.5) + 
  geom_line(aes(y = pred), colour = "red")

```

# Relação entre totalPr e condUsed

```{r}

modelo4 = lm(totalPr ~ cond, data= mario2)
tidy(modelo4)
glance(modelo4)

tidy(modelo4, conf.int = TRUE, conf.level = .95) %>% select(-p.value)

```

```{r}

mario2 %>% 
  add_predictions(model = modelo3) %>% # add o que o modelo estima p cada hs_grad
  ggplot(mapping = aes(x = cond, y = totalPr)) + 
  geom_point(alpha = 0.9, size = 1.5) + 
  geom_line(aes(y = pred), colour = "red")

```
